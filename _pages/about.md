---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


I am currently an associate professor at the State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University. I obtained my Ph.D degree from Beihang University in November 2021, supervised by Prof. <a href='http://cvteam.net/members/lijia/upload/index.html'>Jia Li</a>. From November 2021 to January 2024, he engaged in Boya postdoctoral researcher at the National Engineering Research Center of Visual Technology at Peking University, working with Prof. <a href='https://www.pkuml.org/staff/yhtian.html'>Yonghong Tian</a>. 

My research interests include multi-modal visual understanding, fine-grained visual object analysis, and AR/VR content generation. I have published more than 27 CCF-A papers such as TPAMI, IJCV, CVPR/ICCV, and NeurIPS, and was awarded the Outstanding Reviewer of ICCV2021 and NeurIPS2023 and the Champion of FGVC8-iMET Challenge of the CVPR2021 Conference. <a href='https://scholar.google.com/citations?user=bUzykm0AAAAJ'> <img alt="Google Scholar" src="https://img.shields.io/badge/Google-Scholar-blue"></a> 


 

He is a member of <a href='https://cvteam.buaa.edu.cn/'>CVTEAM</a>. 
Lab Page: <img alt="CVTEAM" src="https://img.shields.io/badge/Lab-CVTEAM-blue">  <a href='https://cvteam.buaa.edu.cn/'></a> 
Github Page: <a href='https://github.com/iCVTEAM'>  <img alt="CVTEAM" src="https://img.shields.io/badge/github-CVTEAM-red"> </a>

Email: zhaoyf@buaa.edu.cn


# üî• News
- *2024.02*: &nbsp;üéâüéâ I joined the School of Computer Science and Engineering, at Beihang University. 

# üìù Publications 

- [Parsing Objects at a Finer Granularity: A Survey](https://arxiv.org/abs/2306.10511), <i>Yifan Zhao, Jia Li<sup>\*</sup>, Yonghong Tian<sup>\*</sup></i> **Machine Intelligence Research (MIR) 2024 [Survey Paper]**

- [Sensitivity Decouple Learning for Image Compression Artifacts Reduction](https://zhao1f.github.io/), <i>Li Ma<sup>#</sup>, <b>Yifan Zhao<sup>#</sup></b>, Peixi Peng, Yonghong Tian</i>, **IEEE Transactions on Image Processing (TIP), 2024**

- [SpikeNeRF: Learning Neural Radiance Fields from Continuous Spike Stream](https://arxiv.org/pdf/2403.11222), <i>Lin Zhu, Kangmin Jia, <b>Yifan Zhao</b>, Yunshan Qi, Lizhi Wang, Hua Huang</i>, **IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2024**

- [DR2: Disentangled Recurrent Representation Learning for Data-Efficient Speech Video Synthesis](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_DR2_Disentangled_Recurrent_Representation_Learning_for_Data-Efficient_Speech_Video_Synthesis_WACV_2024_paper.pdf), <i>Chenxu Zhang, Chao Wang, <b>Yifan Zhao</b>, Shuo Cheng, Linjie Luo, Xiaohu Guo</i>, **Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024**

- [Dual Adaptive Representation Alignment for Cross-domain Few-shot Learning](https://arxiv.org/abs/2306.10511), <i> <b>Yifan Zhao<sup>#</sup></b>, Zhang Tong<sup>#</sup>, Li Jia<sup>\*</sup>, Tian Yonghong<sup>\*</sup></i>, **IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI) 2023**

- [Semantic Contrastive Bootstrapping for Single-positive Multi-label Recognition](https://arxiv.org/pdf/2307.07680), <i> Cheng Chen<sup>#</sup>, <b>Yifan Zhao<sup>#</sup></b>, Li Jia<sup>\*</sup></i>, **International Journal of Computer Vision (IJCV) 2023**

- [Hierarchical Adaptive Value Estimation for Multi-modal Visual Reinforcement Learning](https://openreview.net/pdf?id=jB4wsc1DQW), <i>Yangru Huang, Peixi Peng, <b>Yifan Zhao</b>, Haoran Xu, Mengyue Geng, Yonghong Tian</i>, **Advances in Neural Information Processing Systems (NeurIPS) 2023**

- [Simoun: Synergizing Interactive Motion-appearance Understanding for Vision-based Reinforcement Learning](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Simoun_Synergizing_Interactive_Motion-appearance_Understanding_for_Vision-based_Reinforcement_Learning_ICCV_2023_paper.html), <i>Yangru Huang, Peixi Peng, <b>Yifan Zhao</b>, Yunpeng Zhai, Haoran Xu, Yonghong Tian</i>, **IEEE International Conference on Computer Vision (ICCV) 2023**

- [Stabilizing Visual Reinforcement Learning via Asymmetric Interactive Cooperation](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Stabilizing_Visual_Reinforcement_Learning_via_Asymmetric_Interactive_Cooperation_ICCV_2023_paper.pdf), <i>Yunpeng Zhai, Peixi Peng, <b>Yifan Zhao</b>, Yangru Huang, Yonghong Tian</i>, **IEEE International Conference on Computer Vision (ICCV) 2023**

- [Learning with Fantasy: Semantic-Aware Virtual Contrastive Constraint for Few-Shot Class-Incremental Learning](https://openaccess.thecvf.com/content/CVPR2023/html/Song_Learning_With_Fantasy_Semantic-Aware_Virtual_Contrastive_Constraint_for_Few-Shot_Class-Incremental_CVPR_2023_paper.html), <i>Zeyin Song<sup>#</sup>, <b>Yifan Zhao<sup>#</sup></b>, Yujun Shi, Peixi Peng<sup>\*</sup>, Li Yuan, Yonghong Tian<sup>\*</sup></i>, **IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2023**

- [Invariant and consistent: Unsupervised representation learning for few-shot visual recognition](https://github.com/iCVTEAM/InCo), <i>Heng Wu,<b>Yifan Zhao</b>, Jia Li<sup>\*</sup></i>, **Neurocomputing 2023**

- [Â±ÄÈÉ®ÂÖ≥Á≥ªÊ≥õÂåñË°®ÂæÅÁöÑÂ∞èÊ†∑Êú¨Â¢ûÈáèÂ≠¶‰π†](https://github.com/iCVTEAM/G-FSCIL), <i><b>Ëµµ‰∏ÄÂá°</b>Ôºå ÊùéÁî≤<sup>\*</sup>Ôºå Áî∞Ê∞∏È∏ø<sup>\*</sup></i>, **‰∏≠ÂõΩÁßëÂ≠¶Ôºö‰ø°ÊÅØÁßëÂ≠¶ 2023 (CCF-A‰∏≠ÊñáÊúüÂàä)**

- [From Pose to Part: Weakly-Supervised Pose Evolution for Human Part Segmentation](https://ieeexplore.ieee.org/document/9772949), <i> <b>Yifan Zhao</b>, Yu Zhang, Li Jia<sup>\*</sup>, Tian Yonghong</i>, **IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI) 2022**

- [Joint self-supervised and reference-guided learning for depth inpainting
](https://link.springer.com/content/pdf/10.1007/s41095-021-0259-z.pdf), <i>Heng Wu, Kui Fu, <b>Yifan Zhao</b>, Haokun Song, Jia Li</i>, **Computational Visual Media (CVMJ) 2022**




<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[xxxxxxxxxxxxxxxxxxxxxPage ](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Yifan Zhao**, , XXX

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# üìñ Education and Experiences
- *2021.11 - 2024.01*, Boya postdoctoral researcher, Peking University. 
- *2016.09 - 2021.10*, Ph.D., Beihang University. 
- *2012.09 - 2016.06*, B.Eng, Harbin Institute of Technology. 


# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 




<!--
# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
-->


